{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5475ea",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "384a22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as sf\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d0df2",
   "metadata": {},
   "source": [
    "Creating our Spark Session and suppressing harmless warning messages to reduce clutter in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"FATAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07e8b6",
   "metadata": {},
   "source": [
    "Reading our data from the data lake. The source is a JSON formatted multi-line file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a3999d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"multiline\", \"true\").json(\"../parsed_output/all_dns.json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e60d53",
   "metadata": {},
   "source": [
    "We select only the DNS specific/relevant fields from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "451e07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dns_data = df.select(\"timestamp\",\"src_ip\", \"dst_ip\",\"id\", \"opcode\",\"qr\",\"rcode\",\"questions\",\"answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6615c9",
   "metadata": {},
   "source": [
    "We split the datasets into various categories. Valid queries and responses are those with a non-empty question or answer. Questions have ```qr = 0 ``` while answers have ``` qr == 1```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "239c6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = dns_data.filter((dns_data[\"opcode\"] == 0) & (dns_data[\"qr\"] == 0))\n",
    "all_responses = dns_data.filter((dns_data[\"opcode\"] == 0) & (dns_data[\"qr\"] == 1))\n",
    "valid_queries = all_queries.filter(sf.size(\"questions\") > 0).drop(\"answers\")\n",
    "valid_responses = all_responses.filter(sf.size(\"answers\") > 0).drop(\"questions\")\n",
    "empty_questions = all_queries.filter(sf.size(\"questions\") == 0)\n",
    "empty_answers = all_responses.filter(sf.size(\"answers\") == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d32e18",
   "metadata": {},
   "source": [
    "The summary dataframe below gives us an initial feel of the breakdown of our dataset. We will perform our analysis on specific datasets, and also correlate between datasets later for deeper insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9acf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data =[{\"Total DNS Records\": dns_data.count(),\n",
    "                \"All Queries\": all_queries.count(),\n",
    "                \"All Responses\": all_responses.count(),\n",
    "                \"Valid (non-empty) Questions\": valid_queries.count(),\n",
    "                \"Valid (non-empty) Answers\": valid_responses.count()\n",
    "                }]\n",
    "summary = spark.createDataFrame(summary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8533879",
   "metadata": {},
   "source": [
    "We now explode the questions arrays to extract the individual fields from the DNS request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e60d068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_queries = valid_queries.withColumn(\"questions\", sf.explode(\"questions\"))\n",
    "valid_queries = valid_queries.withColumns({\n",
    "    \"qname\": valid_queries.questions.qname,\n",
    "    \"qtype\": valid_queries.questions.qtype,\n",
    "    \"qlen\": sf.length(valid_queries.questions.qname)}).drop(\"questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e59cdd",
   "metadata": {},
   "source": [
    "Similary, we explode the answers array to extract the individual answer fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f4aa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_responses = valid_responses.withColumn(\"answers\", sf.explode(\"answers\")).drop(\"questions\")\n",
    "valid_responses = valid_responses.withColumns({\n",
    "    \"rclass\":valid_responses.answers.rclass,\n",
    "    \"rdata\": valid_responses.answers.rdata,\n",
    "    \"rrname\": valid_responses.answers.rrname,\n",
    "    \"rtype\": valid_responses.answers.rtype,\n",
    "    \"ttl\": valid_responses.answers.ttl\n",
    "}).drop(\"answers\", \"opcode\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a903ec6",
   "metadata": {},
   "source": [
    "We rename the fields in the ```valid_responses``` dataframe to avoid conflicts with the ```valid_queries``` dataframe when we perform a join later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e168785",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_responses = valid_responses.withColumnsRenamed({\n",
    "    \"timestamp\": \"ts\",\n",
    "    \"src_ip\": \"ns\",\n",
    "    \"dst_ip\": \"client_ip\",\n",
    "    \"id\": \"rid\",\n",
    "    \"qr\": \"rqr\",\n",
    "    \"rcode\": \"rrcode\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce07e1",
   "metadata": {},
   "source": [
    "Now that we have prepared our dataset, we will persist to storage as ```.parquet``` format, for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8a8aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_queries.write.parquet(\"../datasets/valid_queries.parquet\", mode=\"overwrite\")\n",
    "valid_responses.write.parquet(\"../datasets/valid_responses.parquet\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
